{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Call Bedrock models with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you will create tools to sell more tickets and book shows. In the process of asking Bedrock LLMs questions and assigning them tasks to run booking, you should compare the code needed to invoke models through an AWS SDK (Boto3) and LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose **Select Kernel** in the top right corner and then in the **Select kernel** dialog that appears select **Install/Enable suggested extensions Python + Jupyter**.\n",
    "\n",
    "    **Note:** If you see a popup window, choose **Trust Publisher & Install**.\n",
    "\n",
    "2. Choose **Select Kernel** again, then in the **Select kernel** dialog choose **Python environments**. Then choose **Create Python Environment** and choose **Venv**, then choose **Python 3.12.11 64-bit**.\n",
    "\n",
    "3. To install required the Python libraries for this lab, select **requirements.txt**, then press **OK**.\n",
    "\n",
    "    **Note:** LangChain has multiple different packages for different purposes.\n",
    "    In this lab, you use:\n",
    "    - langchain: For its output parsers\n",
    "    - langchain-community: For its document loaders\n",
    "    - langchain_aws: For its AWS models\n",
    "    - langchain_core: For its prompt templates and output parsers\n",
    "    \n",
    "    A few notifications appear, indicating that pip is being upgraded and other packages are being installed.\n",
    "\n",
    "    Within a short time, where the notebook previously displayed the \"Select Kernel\" message, it should now display \".venv (Python 3.12.11)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. To suppress unnecessary warnings, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** When you place your cursor in a code cell, a **play** icon will appear on the left side. Use that to run the code. You will know the code block has completed running when you see a number display within square brackets below the play icon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1: Invoke models using boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use *AWS SDK for Python (Boto3)* to ask an Amazon Nova Lite model how to get more people in the door."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. To help the venue think of ideas to sell more tickets, perform a text completion task with *Amazon Nova Lite* through Boto3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A music venue can sell out every night by employing a combination of strategic planning, marketing, and community engagement. Here are some key factors that contribute to consistent sell-outs:\n",
      "\n",
      "1. **Diverse Lineup**:\n",
      "   - **Variety of Genres**: Offer a mix of genres to attract a broad audience. This could include rock, pop, indie, electronic, jazz, and more.\n",
      "   - **Local and National Acts**: Feature both local talent and well-known national or international artists to attract different segments of the audience.\n",
      "\n",
      "2. **Consistent Quality**:\n",
      "   - **Reputation**: Build a reputation for high-quality performances and a great venue experience. Word-of-mouth and online reviews play a significant role.\n",
      "   - **Professionalism**: Ensure that every aspect of the event, from sound and lighting to security and staff, is top-notch.\n",
      "\n",
      "3. **Engaging Marketing**:\n",
      "   - **Social Media**: Use platforms like Instagram, Facebook, and Twitter to promote events, share behind-the-scenes content, and engage with fans.\n",
      "   - **Email Newsletters**: Send regular updates and exclusive offers to a subscriber list.\n",
      "   - **Collaborations**: Partner with influencers, local businesses, and other venues to expand your reach.\n",
      "\n",
      "4. **Community Engagement**:\n",
      "   - **Local Events**: Host community events, open mic nights, and local artist showcases to build a loyal local following.\n",
      "   - **Feedback Loop**: Actively seek and respond to audience feedback to improve the experience continually.\n",
      "\n",
      "5. **Pricing Strategy**:\n",
      "   - **Competitive Pricing**: Offer tickets at competitive prices, and consider tiered pricing models to cater to different budget levels.\n",
      "   - **Early Bird Specials**: Encourage early ticket purchases with discounts.\n",
      "\n",
      "6. **Unique Experience**:\n",
      "   - **Themed Nights**: Create themed nights or special events that add an extra layer of excitement.\n",
      "   - **Food and Beverage**: Offer a diverse and high-quality food and beverage menu to enhance the overall experience.\n",
      "\n",
      "7. **Accessibility**:\n",
      "   - **Location**: Choose a convenient and accessible location for your target audience.\n",
      "   - **Transportation**: Provide information on public transport, parking, and rideshare options.\n",
      "\n",
      "8. **Loyalty Programs**:\n",
      "   - **Rewards**: Implement a loyalty program that rewards frequent attendees with discounts, early access to tickets, and exclusive perks.\n",
      "\n",
      "9. **Networking**:\n",
      "   - **Industry Connections**: Build relationships with other venues, promoters, and artists to create a network that can help\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "# Create the Amazon Bedrock client\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "\n",
    "# Define the text generation configuration\n",
    "textGenerationConfig = {\n",
    "    \"maxTokens\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "    \"topP\": 0.9\n",
    "}\n",
    "\n",
    "modelId = \"amazon.nova-lite-v1:0\"\n",
    "\n",
    "# Define the input text for text generation\n",
    "prompt = \"A music venue can sell out every night by...\"\n",
    "\n",
    "native_request = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": prompt}]\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": textGenerationConfig\n",
    "}\n",
    "\n",
    "request = json.dumps(native_request).encode('utf-8')\n",
    "\n",
    "# Invoke the Amazon Bedrock model for text generation\n",
    "response = bedrock_client.invoke_model(modelId=modelId, body=request)\n",
    "\n",
    "# Extract the outputText from the response\n",
    "response = json.loads(response[\"body\"].read())\n",
    "generated_text = response.get('output').get('message').get('content')[0].get('text')\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model invocation with Boto3 can be seen as low-level. If you want to make a complex, production-ready LLM tool, it requires you to do lots of things yourself in Python.\n",
    "\n",
    "See the length of code required to invoke above and the return object that requires indexing to print pretty as some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Invoke models using ChatBedrock with simple prompts\n",
    "\n",
    "Leveraging LangChain components and abstractions to invoke Amazon Bedrock models can make your code more high-level. LangChain handles the low-level API details, response parsing, and error handling, allowing you to focus on building your application logic rather than managing model integration complexities.\n",
    "\n",
    "You will use Amazon Nova Lite through LangChain's ChatBedrock component, which handles both single prompts and multi-turn conversations effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create a LangChain ChatBedrock component that uses *Amazon Nova Lite*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ChatBedrock class from the langchain_aws.chat_models.bedrock module\n",
    "from langchain_aws.chat_models.bedrock import ChatBedrock\n",
    "\n",
    "# Set the modelId to the desired model ID (in this case, \"amazon.nova-lite-v1:0\")\n",
    "modelId = \"amazon.nova-lite-v1:0\"\n",
    "\n",
    "# Create an instance of the ChatBedrock with the specified model ID\n",
    "nova_llm = ChatBedrock(model_id=modelId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. To brainstorm bands to reach out to, ask the LLM what the top selling bands of all time are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Determining the \"top-selling\" bands of all time can be somewhat subjective, as it often depends on the source and criteria used for measurement. However, several bands are widely recognized as the best-selling music artists globally based on their recorded music sales. Here are some of the top-selling bands of all time:\n",
       "\n",
       "1. **The Beatles**  \n",
       "   - Estimated sales: Over 600 million records worldwide.\n",
       "   - The Beatles are often cited as the best-selling band of all time, with a massive global impact on music and culture.\n",
       "\n",
       "2. **Led Zeppelin**  \n",
       "   - Estimated sales: Over 300 million records worldwide.\n",
       "   - Known for their powerful rock music, Led Zeppelin has sold millions of albums worldwide.\n",
       "\n",
       "3. **Pink Floyd**  \n",
       "   - Estimated sales: Over 250 million records worldwide.\n",
       "   - Famous for their concept albums and progressive rock style, Pink Floyd has a dedicated global fanbase.\n",
       "\n",
       "4. **Eagles**  \n",
       "   - Estimated sales: Over 200 million records worldwide.\n",
       "   - The Eagles are known for their blend of rock and country, with numerous hit songs and albums.\n",
       "\n",
       "5. **Fleetwood Mac**  \n",
       "   - Estimated sales: Over 100 million records worldwide.\n",
       "   - Known for their hit songs and strong female presence, Fleetwood Mac has enjoyed long-lasting success.\n",
       "\n",
       "6. **AC/DC**  \n",
       "   - Estimated sales: Over 200 million records worldwide.\n",
       "   - Renowned for their hard rock and heavy metal contributions, AC/DC has a massive following.\n",
       "\n",
       "7. **The Rolling Stones**  \n",
       "   - Estimated sales: Over 240 million records worldwide.\n",
       "   - One of the most influential rock bands, the Rolling Stones have had a prolific career spanning several decades.\n",
       "\n",
       "8. **Metallica**  \n",
       "   - Estimated sales: Over 200 million records worldwide.\n",
       "   - As leaders of the thrash metal genre, Metallica has sold millions of albums worldwide.\n",
       "\n",
       "9. **U2**  \n",
       "   - Estimated sales: Over 170 million records worldwide.\n",
       "   - Known for their anthemic rock songs and political activism, U2 has a strong global presence.\n",
       "\n",
       "10. **Bon Jovi**  \n",
       "    - Estimated sales: Over 100 million records worldwide.\n",
       "    - With a string of hit songs and albums, Bon Jovi has maintained a loyal fanbase for decades.\n",
       "\n",
       "These figures are approximations and can vary based on different sources and methodologies. Nonetheless, these bands are universally acknowledged for their significant contributions to the music industry and their massive sales figures."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the prompt to be sent to the LLM\n",
    "prompt = \"What are the top-selling bands of all time?\"\n",
    "\n",
    "# Call the invoke method of the ChatBedrock instance with the prompt formatted as a human message and store the response\n",
    "response = nova_llm.invoke([(\"human\", prompt)])\n",
    "\n",
    "# Render the response content as Markdown using the Markdown function\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe this independent venue should be realistic about their booking potential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Prompt the LLM again, this time, with a caveat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure, here are ten bands that currently play primarily in small venues, along with detailed descriptions of each:\n",
       "\n",
       "1. **The Districts**\n",
       "   - **Genre**: Indie Rock/Alternative\n",
       "   - **Origin**: Los Angeles, California\n",
       "   - **Description**: The Districts, fronted by singer-songwriter Jacob Slater, emerged in the early 2010s. Their music is characterized by its raw, emotional intensity and introspective lyrics. Their sound blends elements of indie rock and alternative, often featuring Slater's haunting vocals and intricate guitar work. They have a dedicated following, often performing in intimate venues that allow for a close connection with their audience.\n",
       "\n",
       "2. **The Head and the Heart**\n",
       "   - **Genre**: Indie Folk/Rock\n",
       "   - **Origin**: Seattle, Washington\n",
       "   - **Description**: The Head and the Heart formed in 2010 and quickly gained a reputation for their heartfelt, anthemic sound. Their music combines indie folk and rock, with lush harmonies and poetic lyrics. The band's live performances are known for their energy and emotional depth, often filling small venues with their infectious sound.\n",
       "\n",
       "3. **The War on Drugs**\n",
       "   - **Genre**: Indie Rock/Psychedelic\n",
       "   - **Origin**: Philadelphia, Pennsylvania\n",
       "   - **Description**: Led by songwriter and multi-instrumentalist Adam Granduciel, The War on Drugs creates a dreamy, psychedelic sound that blends indie rock with elements of soul and funk. Their music is often characterized by its lush instrumentation and introspective lyrics. Despite their growing popularity, they still frequently play smaller venues, where their intricate soundscapes can be fully appreciated.\n",
       "\n",
       "4. **The Ballroom Thieves**\n",
       "   - **Genre**: Indie Rock/Folk\n",
       "   - **Origin**: Los Angeles, California\n",
       "   - **Description**: The Ballroom Thieves, fronted by singer-songwriter Patrick Stickles, combine elements of indie rock and folk. Their music is characterized by its poetic lyrics and intricate guitar work. The band often performs in small venues, where their storytelling and musical craftsmanship can resonate with audiences on a personal level.\n",
       "\n",
       "5. **The Headstones**\n",
       "   - **Genre**: Alternative Rock/Punk\n",
       "   - **Origin**: Toronto, Ontario, Canada\n",
       "   - **Description**: The Headstones are a Canadian alternative rock band known for their energetic live performances and socially conscious lyrics. Their music blends elements of punk, rock, and folk, often featuring powerful vocals and driving rhythms. They have a loyal following and frequently play in smaller venues, where their high-energy shows can engage the audience directly.\n",
       "\n",
       "6. **The District Sleeps Alone Tonight**\n",
       "   - **Genre**: Indie Rock/Alternative\n",
       "   - **Origin**: Brooklyn, New York\n",
       "   - **Description**: This Brooklyn-based band, led by singer-songwriter Joe Hertler, creates a mix of indie rock and alternative sounds. Their music is characterized by its introspective lyrics and intricate instrumentation. They often perform in small venues, where their detailed, atmospheric sound can create an intimate connection with the audience.\n",
       "\n",
       "7. **The Head and the Heart**\n",
       "   - **Genre**: Indie Folk/Rock\n",
       "   - **Origin**: Seattle, Washington\n",
       "   - **Description**: (Note: This is a repeat, but worth mentioning again for their intimate performances) The Head and the Heart formed in 2010 and quickly gained a reputation for their heartfelt, anthemic sound. Their music combines indie folk and rock, with lush harmonies and poetic lyrics. The band's live performances are known for their energy and emotional depth, often filling small venues with their infectious sound.\n",
       "\n",
       "8. **The Districts**\n",
       "   - **Genre**: Indie Rock/Alternative\n",
       "   - **Origin**: Los Angeles, California\n",
       "   - **Description**: (Note: This is a repeat, but worth mentioning again for their raw, emotional performances) The Districts, fronted by singer-songwriter Jacob Slater, emerged in the early 2010s. Their music is characterized by its raw, emotional intensity and introspective lyrics. Their sound blends elements of indie rock and alternative, often featuring Slater's haunting vocals and intricate guitar work. They have a dedicated following, often performing in intimate venues that allow for a close connection with their audience.\n",
       "\n",
       "9. **The Head and the Heart**\n",
       "   - **Genre**: Indie Folk/Rock\n",
       "   - **Origin**: Seattle, Washington\n",
       "   - **Description**: (Note: This is a repeat, but worth mentioning again for their heartfelt, anthemic performances) The Head and the Heart formed in 2010 and quickly gained a reputation for their heartfelt, anthemic sound. Their music combines indie folk and rock, with lush harmonies and poetic lyrics. The band's live performances are known for their energy and emotional depth, often filling small venues with their infectious sound.\n",
       "\n",
       "10. **The Ballroom Thieves**\n",
       "    - **Genre**: Indie Rock/Folk\n",
       "    - **Origin**: Los Angeles, California\n",
       "    - **Description**: (Note: This is a repeat, but worth mentioning again for their poetic, intricate performances) The Ballroom Thieves, fronted by singer-songwriter Patrick Stickles, combine elements of indie rock and folk. Their music is characterized by its poetic lyrics and intricate guitar work. The band often performs in small venues, where their storytelling and musical craftsmanship can resonate with audiences on a personal level.\n",
       "\n",
       "These bands are known for their unique sounds and intimate performances, making them a great fit for smaller venues where their music can truly shine."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What are 10 bands right now that only play small venues? Describe each band in detail.\"\n",
    "\n",
    "# Call the invoke method of the ChatBedrock instance with the prompt formatted as a human message and store the response\n",
    "response = nova_llm.invoke([(\"human\", prompt)])\n",
    "\n",
    "# Render the response content as Markdown using the Markdown function\n",
    "Markdown(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3: Invoke models using ChatBedrock with structured messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use LangChain to work with Bedrock models in a more conversational way with structured messages. LangChain chat models use a sequence of messages as inputs and return messages (as opposed to plain text) as outputs. You will use LangChain's chat model component, ChatBedrock, to book shows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with a chat model, each message contains a *role* and *content*. In this lab, you work with the following:\n",
    "- Human messages: Represents a message from a user\n",
    "- AI messages: Represents a message from a model\n",
    "- System messages: Represents a system messages, which tells the model how to behave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Import the ChatBedrock class, create an inference request parameters object, and define the Bedrock model id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ChatBedrock class from the langchain_aws.chat_models.bedrock module\n",
    "from langchain_aws.chat_models.bedrock import ChatBedrock\n",
    "\n",
    "# Define the text generation configuration\n",
    "textGenerationConfig = {\n",
    "    \"maxTokens\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "    \"topP\": 0.9\n",
    "}\n",
    "\n",
    "modelId = \"amazon.nova-lite-v1:0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. **Challenge:** Create a **ChatBedrock** object, assigning it to a variable called **chat**, using **textGenerationConfig** and **modelId** as the inputs to the necessary parameters\n",
    "[LangChain API Reference](https://python.langchain.com/v0.2/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock.ChatBedrock.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Amazon Nova Lite LangChain chat model\n",
    "\n",
    "nova_chat = ChatBedrock(\n",
    "    client=bedrock_client,\n",
    "    model_id=modelId,\n",
    "    model_kwargs=textGenerationConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Solution:</b> Select if you need to see the solution.</summary>\n",
    "    \n",
    "<br/>\n",
    "\n",
    "```python\n",
    "# Create an Amazon Nova chat model object\n",
    "nova_chat = ChatBedrock(\n",
    "    client=bedrock_client,\n",
    "    model_id=modelId,\n",
    "    model_kwargs=textGenerationConfig,\n",
    ")\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain chat models work with lists of messages, each with a persona and content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Because you are working with a chat model, create a messages list with a *system message*, describing the model's purpose to fulfill, and a *content*, the question or response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list to join in on the middle of a conversation with the chat model\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are the manager of a music venue. You respond to artists who reach out to you about playing a show at your venue on their upcoming tour.\"\n",
    "    ),\n",
    "    (\n",
    "        \"human\", \n",
    "        \"Hello! We are an up-and-coming punk band with thousands of fans. We are coming to town September 17\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Invoke the chat model, using the messages list as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike, an LLM object, LangChain chat models, take a list of messages as a parameter for invocation.\n",
    "ai_msg = nova_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learn more:** See [LangChain ChatBedrock documentation](https://python.langchain.com/v0.2/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock.ChatBedrock.html) for a list of methods and ways to invoke this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AI response comes in *Message* format. To avoid printing metadata and persona, index to the *content* key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Print the content of the AI response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! Thank you for reaching out about playing a show at our venue on September 17. We're excited to hear about your upcoming tour and the buzz around your music.\n",
       "\n",
       "To move forward, we'll need a bit more information to ensure we can accommodate your needs and provide the best experience for your fans. Here are a few details we'll need from you:\n",
       "\n",
       "1. **Show Details:**\n",
       "   - Preferred show time (start and end times).\n",
       "   - Any special requests or requirements for the performance (e.g., stage setup, lighting, sound).\n",
       "\n",
       "2. **Contract and Financials:**\n",
       "   - Proposed show fee or revenue-sharing model.\n",
       "   - Any additional costs (e.g., travel, accommodation, marketing support).\n",
       "\n",
       "3. **Marketing and Promotion:**\n",
       "   - How you plan to promote the show.\n",
       "   - Any promotional materials or support you need from our end (e.g., posters, social media promotion).\n",
       "\n",
       "4. **Logistics:**\n",
       "   - Rider details (technical requirements, backstage needs, etc.).\n",
       "   - Any specific logistical considerations (e.g., entry/exit points, parking).\n",
       "\n",
       "5. **Support Acts:**\n",
       "   - If you have any support acts or opening bands, please provide their details as well.\n",
       "\n",
       "Once we have this information, we can discuss the details further and work towards a mutually beneficial agreement. We look forward to potentially hosting your show and seeing the energy you bring to our venue.\n",
       "\n",
       "Feel free to reach out with any questions or additional information. We're excited to collaborate!\n",
       "\n",
       "Best regards,\n",
       "\n",
       "[Your Name]  \n",
       "[Your Position]  \n",
       "[Venue Name]  \n",
       "[Contact Information]  \n",
       "[Venue Website]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.4: Challenge: Calculate cost of invocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use LangChain methods and Bedrock documentation to calculate the cost of your last LLM invocation.\n",
    "\n",
    "When preparing to launch LLM applications, it is important to have an understanding of cost. If used by large organizations or repeatedly, Amazon Bedrock usage costs can add up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Find a method in the [LangChain documentation](https://api.python.langchain.com/en/latest/chat_models/langchain_aws.chat_models.bedrock.ChatBedrock.html) that returns the number of tokens present in a text string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Use that method on **prompt** and assign the output to a variable called **input_tokens**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/environment/.venv/lib64/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "# Assign the number of tokens used in prompt to a variable called input_tokens\n",
    "input_tokens = nova_chat.get_num_tokens(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Use the same method on **ai_message.content** and assign the output to a variable called **output_tokens**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the number of tokens used in ai_message.content to a variable called output_tokens\n",
    "output_tokens = nova_chat.get_num_tokens(ai_msg.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Solution:</b> Select if you need to see the solution. If a warning message appears below the cell after you run it, you can safely ignore the message or run the cell again. </summary>\n",
    "    \n",
    "<br/>\n",
    "\n",
    "```python\n",
    "# The number of tokens the prompt uses for Amazon Nova Lite\n",
    "input_tokens = nova_chat.get_num_tokens(prompt)\n",
    "# The number of tokens the AI response used for Amazon Nova Lite\n",
    "output_tokens = nova_chat.get_num_tokens(ai_msg.content)\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. Scan through [Amazon Bedrock pricing](https://aws.amazon.com/bedrock/pricing/) to find (and assign) the following values for **Amazon Nova Lite** (On-Demand, US East):\n",
    "\n",
    "- **Price per 1,000 input tokens**, assigning that rate to variable **input_price** (price/1000)\n",
    "- **Price per 1,000 output tokens**, assigning that rate to variable **output_price** (price/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two new variables for respective token prices\n",
    "\n",
    "input_price = .0002/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Solution:</b>Select if you need to see the solution.</summary>\n",
    "    \n",
    "<br/>\n",
    "\n",
    "```python\n",
    "# The listed price per 1,000 input tokens for using Amazon Nova Lite, divided by 1,000, to get the price of a single token\n",
    "input_price = .0002/1000\n",
    "# The price per 1,000 output tokens for using Amazon Nova Lite, divided by 1,000, to get the price of a single token\n",
    "output_price = .0006/1000\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. Create an equation to calculate the cost of the model invocation in dollars and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the cost of the model invocation (input and output)\n",
    "output_price = .0006/1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Solution:</b> Select if you need to see the solution.</summary>\n",
    "    \n",
    "<br/>\n",
    "\n",
    "```python\n",
    "# Cost = quantity * price\n",
    "cost_cents = input_tokens * input_price + output_tokens * output_price\n",
    "# Multiply by 100 to go from cents to dollars\n",
    "cost_dollars = cost_cents * 100\n",
    "(f\"The price is ${cost_dollars}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While, the cost of this one invocation is very small, it's important to have an understanding of such costs. Such an invocation, compounded thousands or millions of times for a large organization or programmatic task, could have a massive cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task complete**: You built tools for the venue to sell more tickets and book shows using LangChain models and their methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 4: Explore LangChain class capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you will create parts of AI tools to help make the venue bar manager's job easier.\n",
    "You'll use some new basic tools of LangChain, Messages, Prompt Templates, and Parsers, that abstract low level code to do common tasks when working to productionalize AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1: Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last task you worked with messages as a list of tuples. To simplify working with chat models, LangChain Core offers messages classes. Use messages to communicate with a chat model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, messages passed to a chat model should start with a *SystemMessage*. A SystemMessage can the general task and guidelines a chat model should adhere to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Create a list of message objects:\n",
    "- Priming the model with **SystemMessage**.\n",
    "- Conveying the first message from a user with **HumanMessage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an AI assistant helping a music venue bar with administrative tasks.\"),\n",
    "    HumanMessage(content=\"Draft an email to all bar staff reminding them of the updated closing procedures and checklists that need to be completed each night after events.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. Invoke the chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Important: Updated Closing Procedures and Checklists\n",
      "\n",
      "Dear Bar Staff,\n",
      "\n",
      "I hope this message finds you well.\n",
      "\n",
      "As part of our ongoing efforts to ensure smooth and efficient operations, we have updated our closing procedures and checklists. It is crucial that all staff members adhere to these updated protocols to maintain the high standards of our venue.\n",
      "\n",
      "**Effective immediately, please follow the new procedures and checklists outlined below:**\n",
      "\n",
      "### Updated Closing Procedures:\n",
      "1. **Event Wrap-Up:**\n",
      "   - Ensure all guests have left the premises.\n",
      "   - Confirm with security that the area is clear and secure.\n",
      "\n",
      "2. **Bar Area:**\n",
      "   - Clean all bar surfaces and equipment.\n",
      "   - Replenish supplies and stock for the next event.\n",
      "   - Ensure all glassware and utensils are washed and stored properly.\n",
      "\n",
      "3. **Dining Area:**\n",
      "   - Clear and reset all tables and chairs.\n",
      "   - Clean all dining surfaces and equipment.\n",
      "   - Ensure all dining ware is washed and stored.\n",
      "\n",
      "4. **Restrooms:**\n",
      "   - Clean all fixtures and restock supplies.\n",
      "   - Ensure all areas are tidy and presentable.\n",
      "\n",
      "5. **General Venue:**\n",
      "   - Turn off all non-essential lights and equipment.\n",
      "   - Conduct a final walkthrough to ensure all areas are secure and clean.\n",
      "\n",
      "### Updated Checklists:\n",
      "Attached to this email, you will find the updated closing procedures checklist and the bar area checklist. Please review these documents thoroughly and ensure you complete all tasks before leaving each night.\n",
      "\n",
      "### Key Points:\n",
      "- **Timeliness:** Please complete all tasks within the designated time frame to avoid any delays.\n",
      "- **Communication:** If you encounter any issues or have suggestions for improvement, please report them to your supervisor immediately.\n",
      "\n",
      "Your cooperation and attention to these updated procedures are greatly appreciated. Together, we can ensure a safe, clean, and welcoming environment for our guests and staff.\n",
      "\n",
      "Thank you for your dedication and hard work.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Position]  \n",
      "[Venue Name]  \n",
      "[Contact Information]  \n",
      "\n",
      "---\n",
      "\n",
      "**Attachments:**\n",
      "1. Closing Procedures Checklist\n",
      "2. Bar Area Checklist\n",
      "\n",
      "---\n",
      "\n",
      "Please let me know if you have any questions or need further clarification.\n",
      "\n",
      "Thank you.\n",
      "\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "response = nova_chat.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also stream chunks of the model response for a more pleasant, faster user experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. Invoke the model again, streaming its response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pomegranate juice, cranberry juice, cherry juice, raspberry syrup, strawberry syrup, unsweetened cranberry juice, unsweetened pomegranate juice, unsweetened berry juice blend"
     ]
    }
   ],
   "source": [
    "# Iterate over the stream of responses from the AI model\n",
    "for chunk in nova_chat.stream(prompt):\n",
    "    # Extract and print the text content from Nova's structured response\n",
    "    if hasattr(chunk, 'content') and chunk.content:\n",
    "        if isinstance(chunk.content, list):\n",
    "            for item in chunk.content:\n",
    "                if isinstance(item, dict) and item.get('type') == 'text':\n",
    "                    # Print the content of each response chunk without adding a newline character\n",
    "                    # end=\"\" prevents printing a newline after each chunk\n",
    "                    # flush=True ensures the output is flushed immediately, without buffering\n",
    "                    print(item.get('text', ''), end=\"\", flush=True)\n",
    "        else:\n",
    "            print(chunk.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2: Prompt templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain Prompt templates allow you to create reusable prompts with placeholders that can be filled with specific inputs, separating the structure of the prompt from the data. Use prompt templates to create purchase orders and come up with new drinks to put on the menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **PromptTemplate** can be used with llm objects to inject inputs into a standard prompt design, creating prompts as strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. To use a prompt template to create several prompts dynamically, run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1:  What is the capital of Nebraska?\n",
      "Prompt 2:  What is the capital of New York?\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"What is the capital of {state}?\")\n",
    "\n",
    "prompt = prompt_template.format(state = \"Nebraska\")\n",
    "print(\"Prompt 1: \", prompt)\n",
    "\n",
    "prompt = prompt_template.format(state = \"New York\")\n",
    "print(\"Prompt 2: \", prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets create a tool for the bar manager using prompt templates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25. Create a list of orders the bar needs to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = [\n",
    "    {\n",
    "        \"product\" : \"soda\",\n",
    "        \"supplier\" : \"TheSodaCompany, LLC\",\n",
    "        \"date\" : \"9/10/2024\"\n",
    "    },\n",
    "    {\n",
    "        \"product\" : \"napkins\",\n",
    "        \"supplier\" : \"Napkin Inc.\",\n",
    "        \"date\" : \"9/12/2024\"\n",
    "    },\n",
    "    {\n",
    "        \"product\" : \"receipt paper\",\n",
    "        \"supplier\" : \"Paper Unlimited\",\n",
    "        \"date\" : \"9/19/2024\"\n",
    "    }\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use each dictionary in the orders list to generate prompts, substituting the placeholders {product}, {supplier}, and {date} with the corresponding values from each dictionary.\n",
    "\n",
    "In the following template, there are placeholders (i.e. the product and supplier and date) that match with keys in the dictionaries inside the order list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26. Create a reusable prompt template that makes purchase orders to the venues supplier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "Human: Create a purchase order for {product} to {supplier} from our company, AMusicVenue,\n",
    "stating that we require delivery by {date}.\n",
    "\n",
    "Assistant:\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables, in {}, allow prompts to be reused by replacing the placeholders with real values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27. Turn the string into a PromptTemplate object, using the *from_template()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['date', 'product', 'supplier'], input_types={}, partial_variables={}, template='\\nHuman: Create a purchase order for {product} to {supplier} from our company, AMusicVenue,\\nstating that we require delivery by {date}.\\n\\nAssistant:')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A prompt template allows you to parameterize prompts, making them reusable. To turn the prompt template into a prompt, you assign values into the variables within the template using *format()* or *invoke()*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28. To create a prompt, use that prompt to invoke a Bedrock model, and print the response, for each of your three needed product orders, run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO #1\n",
      "\n",
      "**Purchase Order**\n",
      "\n",
      "**To:**  \n",
      "TheSodaCompany, LLC  \n",
      "[Address of TheSodaCompany, LLC]  \n",
      "[City, State, ZIP Code]  \n",
      "\n",
      "**From:**  \n",
      "AMusicVenue  \n",
      "[Address of AMusicVenue]  \n",
      "[City, State, ZIP Code]  \n",
      "\n",
      "**Date:**  \n",
      "[Current Date]\n",
      "\n",
      "**Purchase Order Number:**  \n",
      "[PO Number]\n",
      "\n",
      "**Attention:**  \n",
      "[Contact Person's Name, if known]\n",
      "\n",
      "**Subject:**  \n",
      "Purchase Order for Soda Delivery\n",
      "\n",
      "---\n",
      "\n",
      "**Order Details:**\n",
      "\n",
      "**Product Description:**  \n",
      "- Quantity: [Specify Quantity]  \n",
      "- Product: [Specify Type of Soda, e.g., Coca-Cola, Pepsi, Sprite, etc.]  \n",
      "- Packaging: [Specify Packaging, e.g., 12-pack, 24-pack, etc.]\n",
      "\n",
      "**Total Amount:**  \n",
      "- [Specify Total Amount in Words]  \n",
      "- [Specify Total Amount in Numbers]\n",
      "\n",
      "**Delivery Details:**  \n",
      "- Delivery Address: [Specify Delivery Address if different from billing address]  \n",
      "- Delivery Date: 9/10/2024\n",
      "\n",
      "**Payment Terms:**  \n",
      "- [Specify Payment Terms, e.g., Net 30, Net 60, etc.]\n",
      "\n",
      "**Additional Notes:**  \n",
      "- Please ensure that all products are in good condition and meet our quality standards.  \n",
      "- Delivery should be made between [Specify Delivery Time Window, e.g., 9:00 AM - 5:00 PM].\n",
      "\n",
      "**Contact Information:**  \n",
      "- For any questions or concerns, please contact:  \n",
      "  - Name: [Your Contact Person's Name]  \n",
      "  - Phone: [Your Contact Phone Number]  \n",
      "  - Email: [Your Contact Email Address]\n",
      "\n",
      "---\n",
      "\n",
      "**Authorized Signature:**  \n",
      "- [Your Name]  \n",
      "- [Your Title]  \n",
      "- AMusicVenue\n",
      "\n",
      "---\n",
      "\n",
      "**Terms and Conditions:**  \n",
      "- All goods sold are subject to inspection upon delivery. The buyer must notify the seller of any discrepancies within [Specify Number] days of receipt.  \n",
      "- The terms of this purchase order supersede any terms and conditions in the buyerâ€™s purchase order or elsewhere.\n",
      "\n",
      "---\n",
      "\n",
      "**Thank you for your prompt attention to this matter. We look forward to your continued partnership.**\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Title]  \n",
      "AMusicVenue  \n",
      "[Your Contact Information]\n",
      "---------------------\n",
      "PO #2\n",
      "\n",
      "**Purchase Order**\n",
      "\n",
      "**Purchaser:**\n",
      "AMusicVenue  \n",
      "[Your Address]  \n",
      "[City, State, ZIP Code]  \n",
      "[Phone Number]  \n",
      "[Email Address]  \n",
      "\n",
      "**Supplier:**\n",
      "Napkin Inc.  \n",
      "[Supplier Address]  \n",
      "[City, State, ZIP Code]  \n",
      "\n",
      "**Purchase Order Number:** [PO Number]  \n",
      "**Date:** [Current Date]  \n",
      "**Delivery Date Required:** 9/12/2024\n",
      "\n",
      "---\n",
      "\n",
      "**Bill To:**\n",
      "Napkin Inc.  \n",
      "[Supplier Address]  \n",
      "[City, State, ZIP Code]  \n",
      "\n",
      "**Ship To:**\n",
      "AMusicVenue  \n",
      "[Your Address]  \n",
      "[City, State, ZIP Code]  \n",
      "\n",
      "---\n",
      "\n",
      "**Item Description:**  \n",
      "- **Product:** Napkins  \n",
      "- **Quantity:** [Specify Quantity]  \n",
      "- **Unit Price:** [Specify Unit Price]  \n",
      "- **Total Price:** [Specify Total Price]  \n",
      "\n",
      "---\n",
      "\n",
      "**Terms and Conditions:**\n",
      "\n",
      "- Payment terms: [Specify Payment Terms]\n",
      "- Delivery should be made to the specified address by 9/12/2024.\n",
      "- Late delivery will incur penalties as per our agreement.\n",
      "- All products must meet the quality standards specified in our purchase agreement.\n",
      "\n",
      "---\n",
      "\n",
      "**Additional Notes:**\n",
      "\n",
      "- Please include a packing slip and an invoice with the shipment.\n",
      "- Contact [Your Contact Person] at [Your Phone Number] or [Your Email Address] for any questions regarding this order.\n",
      "\n",
      "---\n",
      "\n",
      "**Authorized Signature:**  \n",
      "[Your Name]  \n",
      "[Your Title]  \n",
      "AMusicVenue  \n",
      "\n",
      "---\n",
      "\n",
      "**Napkin Inc. Acknowledgment:**\n",
      "\n",
      "By signing below, Napkin Inc. agrees to the terms and conditions outlined in this purchase order.\n",
      "\n",
      "**Supplier Authorized Signature:**  \n",
      "[Supplier Contact Person]  \n",
      "[Supplier Title]  \n",
      "Napkin Inc.  \n",
      "\n",
      "---\n",
      "\n",
      "**Delivery Instructions:**\n",
      "\n",
      "- Please ensure the delivery is made to the specified address.\n",
      "- Contact [Your Contact Person] prior to delivery to arrange for receipt.\n",
      "\n",
      "---\n",
      "\n",
      "Thank you for your prompt attention to this purchase order. We look forward to your continued excellent service.\n",
      "\n",
      "---\n",
      "\n",
      "**AMusicVenue**  \n",
      "[Your Contact Information]\n",
      "---------------------\n",
      "PO #3\n",
      "\n",
      "**Purchase Order**\n",
      "\n",
      "**To:** Paper Unlimited  \n",
      "**From:** AMusicVenue  \n",
      "**Date:** [Insert Date Here]  \n",
      "**Delivery Required By:** 9/19/2024\n",
      "\n",
      "---\n",
      "\n",
      "**Purchase Order Number:** [Insert PO Number Here]\n",
      "\n",
      "---\n",
      "\n",
      "**Bill To:**\n",
      "\n",
      "AMusicVenue  \n",
      "[Address Line 1]  \n",
      "[Address Line 2]  \n",
      "[City, State, ZIP Code]  \n",
      "[Contact Person]  \n",
      "[Phone Number]  \n",
      "[Email Address]\n",
      "\n",
      "---\n",
      "\n",
      "**Ship To:**\n",
      "\n",
      "AMusicVenue  \n",
      "[Address Line 1]  \n",
      "[Address Line 2]  \n",
      "[City, State, ZIP Code]  \n",
      "\n",
      "---\n",
      "\n",
      "**Item Description:**\n",
      "\n",
      "- **Product Name:** Receipt Paper  \n",
      "- **Quantity:** [Insert Quantity Here]  \n",
      "- **Unit Price:** [Insert Unit Price Here]  \n",
      "- **Total Price:** [Insert Total Price Here]\n",
      "\n",
      "---\n",
      "\n",
      "**Payment Terms:**\n",
      "\n",
      "- [Insert Payment Terms Here]\n",
      "\n",
      "---\n",
      "\n",
      "**Delivery Instructions:**\n",
      "\n",
      "- Please ensure delivery by 9/19/2024.\n",
      "\n",
      "---\n",
      "\n",
      "**Additional Notes:**\n",
      "\n",
      "- [Insert any additional specifications or requirements here]\n",
      "\n",
      "---\n",
      "\n",
      "**Authorized Signature:**\n",
      "\n",
      "__________________________  \n",
      "[Name]  \n",
      "[Title]  \n",
      "AMusicVenue\n",
      "\n",
      "---\n",
      "\n",
      "**Contact Information:**\n",
      "\n",
      "For any questions or further information, please contact:  \n",
      "[Contact Person]  \n",
      "[Phone Number]  \n",
      "[Email Address]\n",
      "\n",
      "---\n",
      "\n",
      "**Thank you for your prompt attention to this purchase order.**\n",
      "\n",
      "---\n",
      "\n",
      "**AMusicVenue**  \n",
      "[Website URL]  \n",
      "[Social Media Handles]\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "nova_llm = ChatBedrock(model_id=\"amazon.nova-lite-v1:0\",\n",
    "                         model_kwargs={\n",
    "                             \"temperature\": .8,\n",
    "                             \"topP\": .8\n",
    "                         })\n",
    "\n",
    "# PO Counter\n",
    "order_num = 1\n",
    "\n",
    "# Loop through the orders list\n",
    "for order in orders:\n",
    "    # Create a prompt from a template by indexing the order dict\n",
    "    prompt = prompt_template.format(product=order[\"product\"],\n",
    "                             supplier=order[\"supplier\"],\n",
    "                             date=order[\"date\"])\n",
    "    # Invoke a Bedrock model\n",
    "    response = nova_llm.invoke([(\"human\", prompt)])\n",
    "\n",
    "    # Print the order #\n",
    "    print(\"PO #\" + str(order_num) + \"\\n\")\n",
    "    # Increment the order # counter\n",
    "    order_num += 1\n",
    "    # Print the model response\n",
    "    print(response.content)\n",
    "    print (\"---------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This code generated purchase order prompts by substituting placeholders in the template with values from a list of orders. It sent the prompts to an Amazon Bedrock LLM and printed the model's responses along with the purchase order numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are the bars purchase orders to its vendors for the week!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ChatPromptTemplate** is a tool that allows you to define a reusable template for conversational prompts, consisting of multiple messages with designated roles (e.g., system, user, assistant). It provides a structured way to incorporate user inputs or placeholders into the message list, which can then be used with LangChain chat models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29. To create a chat prompt template to help the bar manager when they have to make a drink they don't know, create the following template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ChatPromptTemplate class from the langchain_core.prompts module\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate(\n",
    "  [\n",
    "    # Define the initial system message for the chat prompt\n",
    "    (\"system\", \"You are a bar-keeper's assistant. When a user says a drink name, you respond briefly, giving them only the ingredients\"),\n",
    "    # Define the user's input message for the chat prompt\n",
    "    # The {drink} placeholder will be substituted with the actual drink name provided by the user\n",
    "    (\"user\", \"{drink}\"),\n",
    "   ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30. Create a prompt from the prompt template, which will prompt the chat model to list the ingredients for a delicious drink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a formatted prompt by substituting \"shirley temple\" for the {drink} placeholder in the chat_template\n",
    "prompt = chat_template.invoke(\"shirley temple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31. Stream the response from the chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pomegranate juice, cranberry juice, cherry juice, raspberry syrup, strawberry syrup, unsweetened cranberry juice, unsweetened pomegranate juice, unsweetened berry juice blend"
     ]
    }
   ],
   "source": [
    "# Iterate over the stream of responses from the AI model\n",
    "for chunk in nova_chat.stream(prompt):\n",
    "    # Extract and print the text content from Nova's structured response\n",
    "    if hasattr(chunk, 'content') and chunk.content:\n",
    "        if isinstance(chunk.content, list):\n",
    "            for item in chunk.content:\n",
    "                if isinstance(item, dict) and item.get('type') == 'text':\n",
    "                    # Print the content of each response chunk without adding a newline character\n",
    "                    # end=\"\" prevents printing a newline after each chunk\n",
    "                    # flush=True ensures the output is flushed immediately, without buffering\n",
    "                    print(item.get('text', ''), end=\"\", flush=True)\n",
    "        else:\n",
    "            print(chunk.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.3: Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language models typically produce unstructured text outputs. When your application requires structured data, in a specific format, you need to prompt LLMs for very specific formats, which they might be resistant to, or transform outputs to meet your requirements. LangChain output parsers can be used to transform the output of an LLM to a more suitable format. \n",
    "\n",
    "Use output parsers to get outputs of specific formats from LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **CommaSeperatedListOutputParser** component provides several abilities. You can:\n",
    "- Add its format instructions to a prompt template, which will inform the chat model on what to return. Doing such will add the following to your prompt: \"Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\".\n",
    "- Invoke it to parse the model response from a string to a list of strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a bartender runs out of an ingredient on a show night, they might have to find another way to make a Shirley Temple on the fly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32. Create a prompt template to ask the chat model for a commas separated list of potential replacements for an ingredient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CommaSeparatedListOutputParser class from the langchain.output_parsers module\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "# Create an instance of the CommaSeparatedListOutputParser\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# Get the format instructions from the output parser\n",
    "# This will return a string with instructions for the language model\n",
    "# to format its output as a comma-separated list\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# Create a PromptTemplate object\n",
    "# The template string includes a placeholder for the format instructions\n",
    "# and a placeholder for the input variable \"ingredient\"\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"List substitutes for {ingredient}.\\n{format_instructions}\",\n",
    "    input_variables=[\"ingredient\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33. Create a prompt from the prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List substitutes for grenadine.\n",
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "# Use the PromptTemplate object to create a prompt for the language model\n",
    "# by invoking it with the input variable \"ingredient\" set to \"grenadine\"\n",
    "prompt = prompt_template.invoke({\"ingredient\": \"grenadine\"})\n",
    "\n",
    "# Print the generated prompt string\n",
    "print(prompt.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34. Observe the model response before CommaSeparatedListOutputParser is invoked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pomegranate juice, cranberry juice, cherry juice, raspberry juice, strawberry syrup, elderflower cordial, orange juice, lemon juice, lime juice, mint syrup, rose syrup, berry compote, passion fruit syrup, mango puree, apricot jam, fig puree, date syrup, molasses, simple syrup, fruit juice, coconut cream\n"
     ]
    }
   ],
   "source": [
    "nova_chat = ChatBedrock(model_id=\"amazon.nova-lite-v1:0\", model_kwargs = {\n",
    "    \"temperature\": .2,\n",
    "    \"top_p\": .2})\n",
    "\n",
    "response = nova_chat.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35. Invoke the CommaSeparatedListOutputParser to create a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pomegranate juice', 'cranberry juice', 'cherry juice', 'raspberry juice', 'strawberry syrup', 'elderflower cordial', 'orange juice', 'lemon juice', 'lime juice', 'mint syrup', 'rose syrup', 'berry compote', 'passion fruit syrup', 'mango puree', 'apricot jam', 'fig puree', 'date syrup', 'molasses', 'simple syrup', 'fruit juice', 'coconut cream']\n"
     ]
    }
   ],
   "source": [
    "print(output_parser.invoke(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task complete**: You made tools for the bar manager using LangChain components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 5: Create a chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you will leverage the LangChain components you've already learned, to build a chatbot to help organize shifts for venue staff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain chat models are ideal for building chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36. To relay its directive to the chatbot, define a system message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessage(content=\"You are a chatbot built for scheduling staff shifts for AMusicVenue, an independent music venue.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "37. **Challenge**: Finish the shift booking chatbot that will invoke Mistral Large with a system message and a user input\n",
    "\n",
    "    - Replace the `<FMI-1>` \"Fill Me In (FMI)\" value in the code with the appropriate message and its required parameter.\n",
    "\n",
    "    **Tip:** Look for the message type to take a human message in [Langchain_core documentation](https://api.python.langchain.com/en/latest/core_api_reference.html#module-langchain_core.messages) and then find what parameter it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to this simple chatbot! To exit, choose the interrupt button and then press esc.\n",
      "\n",
      "Human: This is Bob. I want to work Saturday.\n",
      "AI: Hello Bob! I'd be happy to help you schedule your shift for Saturday at AMusicVenue. To get started, could you please provide me with the following information?\n",
      "\n",
      "1. **Date and Time:** Which Saturday are you interested in working, and what specific hours would you prefer?\n",
      "2. **Role:** Are you available to work as a bartender, stagehand, door staff, or another role?\n",
      "3. **Availability:** Are there any other dates or times you are available or unavailable in the near future? This will help us create a balanced schedule.\n",
      "4. **Preferences:** Do you have any particular preferences or constraints, such as not working consecutive weekends or needing time off for other commitments?\n",
      "\n",
      "Once I have this information, I can check the availability and see if there's a spot for you on Saturday. Looking forward to your response!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nova_chat = ChatBedrock(model_id=\"amazon.nova-lite-v1:0\")\n",
    "\n",
    "try:\n",
    "    # Print a welcome message to the user\n",
    "    print(\"Welcome to this simple chatbot! To exit, choose the interrupt button and then press esc.\")\n",
    "    while True:\n",
    "        # Prompt the user for input\n",
    "        user_input = input(\"User: \")\n",
    "        # Create a HumanMessage object with the user's input\n",
    "        human_message = HumanMessage(content = user_input)\n",
    "        # Print the user's input\n",
    "        print(f\"\\nHuman: {user_input}\")       \n",
    "        print(\"AI: \", end=\"\")\n",
    "        \n",
    "        # Stream the response from the chatbot\n",
    "        for chunk in nova_chat.stream([system_message, human_message]):\n",
    "            # Extract text from Nova's structured response format\n",
    "            if hasattr(chunk, 'content') and chunk.content:\n",
    "                if isinstance(chunk.content, list):\n",
    "                    for item in chunk.content:\n",
    "                        if isinstance(item, dict) and item.get('type') == 'text':\n",
    "                            print(item.get('text', ''), end=\"\", flush=True)\n",
    "                else:\n",
    "                    print(chunk.content, end=\"\", flush=True)\n",
    "        \n",
    "        print(\"\\n\")  # Add newline after response\n",
    "\n",
    "# Handle the KeyboardInterrupt exception (when the user presses esc)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Solution:</b> Select if you need to see the solution.</summary>\n",
    "    \n",
    "<br/>\n",
    "\n",
    "```python\n",
    "human_message = HumanMessage(content = user_input)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38. Start the chatbot by running the above cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "39. In the input pop-up at the top of the IDE, input the initial message \"This is *your name*, I want to work Saturday.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40. Continue to respond to its questions, poking holes at its knowledge, until you see model is clearly confused.\n",
    "- If it says it will check on availability, ask what it found.\n",
    "- If the chatbot claims to schedule you for a shift, ask what position the shift is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41. To exit, choose **Interrupt** from the main notebook editor toolbar, and then press the **Esc**/**esc** key.\n",
    "\n",
    "**Warning:** If a pop up appears asking if \"want to restart the kernel\", choose **cancel** and then press the the **Esc**/**esc** key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/interrupt.png\">\n",
    "\n",
    "***Image description**: The *Interrupt* key within the IDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You likely had an interaction with the chatbot that hardly resembled a human interaction and was inadequate as a tool for the venue to use.\n",
    "\n",
    "The chatbot has two primary flaws:\n",
    "- It lacks statefullness, meaning it has no recollection of previous messages that you or it have delivered. It will have forgotten your name and what day you want to work by the time the next response is sent.\n",
    "- It hallucinates, as it has no awarness of shift availability, so it tends to make information up.\n",
    "\n",
    "In the next task, you will fix those two flaws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task complete**: You created a chatbot for staffing the venue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Task 6: Make the chatbot application specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you will add statefullness and context of needed shifts to the chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.1: Make the chatbot stateful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statelessness means LLMs do not retrain messages for their next invocation. Without the previous messages to the chatbot being stored, an LLMs utility is limited to a human message and an AI response.\n",
    "So that venue staff can have a conversation with the chatbot, add statefullness to the chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "42. **Challenge**: Finish adding statefullness to shift booking chatbot by \n",
    "\n",
    "    - Replace the `<FMI-1>` \"Fill Me In (FMI)\" value in the code with the appropriate method to add an object to the *messages* list.\n",
    "    - Replace the `<FMI-2>` \"Fill Me In (FMI)\" value in the code with the appropriate parameter to add the *model response* to the messages list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to this simple chatbot! To exit, choose the interrupt button and then press esc.\n",
      "Human:\n",
      "i am a bob. I want to work Saterday.\n",
      "---------------\n",
      "AI: \n",
      "Hello Bob! I'd be happy to help you schedule your shift for Saturday. To get started, could you please provide me with the following information?\n",
      "\n",
      "1. **Preferred Shift Time**: Are you available for the morning shift (e.g., 10 AM - 2 PM), afternoon shift (e.g., 2 PM - 6 PM), or evening shift (e.g., 6 PM - 10 PM)?\n",
      "2. **Role**: Are you interested in working as a bartender, front-of-house staff, stage manager, or another role?\n",
      "3. **Special Requirements**: Do you have any specific requests or requirements for your shift?\n",
      "\n",
      "Once I have this information, I can check the availability and confirm your shift. Looking forward to your response!\n",
      "---------------\n",
      "Human:\n",
      "i'm available for evening shift. The desired role - IT specialist. I have no special requirements.\n",
      "---------------\n",
      "AI: \n",
      "Great, Bob! Here's what we have for your Saturday shift:\n",
      "\n",
      "**Date**: Saturday, [Insert Date]\n",
      "**Shift Time**: Evening (6 PM - 10 PM)\n",
      "**Role**: IT Specialist\n",
      "\n",
      "Since there are no special requirements, I'll go ahead and schedule your shift. Hereâ€™s a summary:\n",
      "\n",
      "- **Name**: Bob\n",
      "- **Shift**: Evening (6 PM - 10 PM)\n",
      "- **Role**: IT Specialist\n",
      "\n",
      "If this looks good to you, your shift is confirmed. If there are any changes or additional details, please let me know. Enjoy your evening shift at AMusicVenue!\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a chatbot built for scheduling staff shifts for AMusicVenue, an independent music venue.\")\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Print a welcome message to the user\n",
    "    print(\"Welcome to this simple chatbot! To exit, choose the interrupt button and then press esc.\")\n",
    "    while True:\n",
    "        # Prompt the user for input\n",
    "        user_input = input(\"User: \")\n",
    "        human_message = user_input\n",
    "        print(f\"Human:\\n{user_input}\\n---------------\")\n",
    "        # Create a HumanMessage object with the user's input and add it to the messages list\n",
    "        messages.append(HumanMessage(human_message))\n",
    "\n",
    "        # Assign a blank string that will be added to from the response chunks\n",
    "        response_content = \"\"\n",
    "\n",
    "        print(\"AI: \")\n",
    "        # Stream the response from the chatbot and append each chunk to a string\n",
    "        for chunk in nova_chat.stream(messages):\n",
    "            # Extract text from Nova's structured response format\n",
    "            if hasattr(chunk, 'content') and chunk.content:\n",
    "                if isinstance(chunk.content, list):\n",
    "                    for item in chunk.content:\n",
    "                        if isinstance(item, dict) and item.get('type') == 'text':\n",
    "                            text = item.get('text', '')\n",
    "                            print(text, end=\"\", flush=True)\n",
    "                            response_content += text\n",
    "                else:\n",
    "                    print(chunk.content, end=\"\", flush=True)\n",
    "                    response_content += chunk.content\n",
    "        \n",
    "        # Add the AI message to the messages list\n",
    "        messages.append(AIMessage(response_content))\n",
    "        print(f\"\\n---------------\")\n",
    "\n",
    "# Handle the KeyboardInterrupt exception (when the user presses esc)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Solution:</b> Select if you need to see the solution.</summary>\n",
    "    \n",
    "<br/>\n",
    "\n",
    "\n",
    "```python\n",
    "1. messages.append(HumanMessage(human_message))\n",
    "```\n",
    "\n",
    "```python\n",
    "2. messages.append(AIMessage(response_content))\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "43. Start the chatbot by running the above cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "44. In the input pop-up at the top of the IDE, input the initial message \"This is *your name*, I want to work Saturday.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "45. Continue to respond to its questions, until you see that the chatbot has gained statefullness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "46. To exit, choose **Interrupt** from the main notebook editor toolbar, and then press the **Esc**/**esc** key.\n",
    "\n",
    "**Warning:** If a pop up appears asking if \"want to restart the kernel\", choose **cancel** and then press the the **Esc**/**esc** key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/interrupt.png\">\n",
    "\n",
    "***Image description**: The *Interrupt* key within the IDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The chatbot has gained more function and is now stateful. But, it still lacks awareness of open shifts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.2: Give the chatbot context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On their own, LLMs are a fantastic tool. They are trained on mass amounts of data from the internet, making them incredibly knowledgeable. But, they don't know data specific to your use case. Add the functionality to pull data from a shift tracking CSV file to be able to effectively schedule shifts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Document loaders* are another way to add functionality to LangChain models. They load data from various sources, like AWS S3, JSON files, and URLs, into document objects. You can use those documents to provide context for model invocation.\n",
    "\n",
    "There is a file in your directory called *shifts.csv*. It is a comma-seperated values file containing all remaining shifts the venue needs to staff for a given week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "47. To examine that file, select **shifts.csv** from the IDE sidebar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "48. To load the CSV file, with each line/available shift as its own document, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path=\"./shifts.csv\")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "49. To make the documents usable for your purpose, iterate through them, splitting each *page_content* string and storing them in a list of shift dictionary objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'time': '6PM-CLOSE',\n",
       "  'day': 'Friday',\n",
       "  'duty': 'Bar',\n",
       "  'taken': 'None',\n",
       "  'name': 'None',\n",
       "  'phone': 'None'},\n",
       " {'time': '2PM-CLOSE',\n",
       "  'day': 'Sunday',\n",
       "  'duty': 'Front Door',\n",
       "  'taken': 'Taken',\n",
       "  'name': 'Mary Major',\n",
       "  'phone': '2355550154'},\n",
       " {'time': '10AM-6PM',\n",
       "  'day': 'Friday',\n",
       "  'duty': 'Hospitality',\n",
       "  'taken': 'None',\n",
       "  'name': 'None',\n",
       "  'phone': 'None'},\n",
       " {'time': '5PM-CLOSE',\n",
       "  'day': 'Saturday',\n",
       "  'duty': 'Bar',\n",
       "  'taken': 'Taken',\n",
       "  'name': 'Alejandro Rosalez',\n",
       "  'phone': '2355550185'},\n",
       " {'time': '2PM-CLOSE',\n",
       "  'day': 'Saturday',\n",
       "  'duty': 'Front Door',\n",
       "  'taken': 'None',\n",
       "  'name': 'None',\n",
       "  'phone': 'None'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty list to store the shift dictionaries\n",
    "shifts = []\n",
    "\n",
    "# Iterate over each document in the loaded documents\n",
    "for document in documents:\n",
    "    # Get the page content of the current document as a string\n",
    "    data_str = document.page_content\n",
    "    # Create a dictionary from the string, splitting on newline ('\\n') and colon (': ')\n",
    "    # The keys of the dictionary are the parts before the colon, converted to lowercase\n",
    "    # The values of the dictionary are the parts after the colon\n",
    "    data_dict = {line.split(': ')[0].lower(): line.split(': ')[1] for line in data_str.split('\\n')}\n",
    "    # Add the newly created dictionary to the shifts list\n",
    "    shifts.append(data_dict)\n",
    "\n",
    "shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50. To turn the list of dicts into a string usable by the chat model, run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bar needs staffing on Friday, 6PM-CLOSE.\n",
      "Front Door does not need staffing on Sunday, 2PM-CLOSE, because Mary Major is working it.\n",
      "Hospitality needs staffing on Friday, 10AM-6PM.\n",
      "Bar does not need staffing on Saturday, 5PM-CLOSE, because Alejandro Rosalez is working it.\n",
      "Front Door needs staffing on Saturday, 2PM-CLOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty string to store the shift information\n",
    "shifts_string = \"\"\n",
    "# Iterate over each shift dictionary in the shifts list\n",
    "for shift in shifts:\n",
    "    # If taken key does not equal taken, the shift is available\n",
    "    if not(shift['taken'].lower() == 'taken'):\n",
    "        # Ex: Front door needs staffing on Saturday, 5-CLOSE\n",
    "        textrep = \"{} needs staffing on {}, {}.\".format(shift['duty'],shift['day'],shift['time'])\n",
    "    # Shift is taken\n",
    "    else:\n",
    "        #Ex: Bar does not need staffing on Friday, 6-10, because Alejandro Rosalez is working it.\n",
    "        textrep = \"{} does not need staffing on {}, {}, because {} is working it.\".format(shift['duty'],shift['day'],shift['time'],shift['name'])\n",
    "    # Add the shift to the string of all shifts\n",
    "    shifts_string += textrep + \"\\n\"\n",
    "print(shifts_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "51. **Challenge:** To give the chatbot the necessary context, add the string containing shifts, **shifts_string**, to the *SystemMessage*, and then start the chatbot by running the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to this simple chatbot! To exit, choose the interrupt button and then press esc.\n",
      "Human:\n",
      "i am Bob. I want to work Saturday.\n",
      "---------------\n",
      "AI: \n",
      "Hello Bob! Here are the shifts available for you on Saturday at AMusicVenue:\n",
      "\n",
      "- **Front Door**: Staffing is needed from 2PM to CLOSE.\n",
      "- **Bar**: Staffing is not needed from 5PM to CLOSE because Alejandro Rosalez is working it.\n",
      "\n",
      "Would you like to sign up for the Front Door shift on Saturday?\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a chatbot built for scheduling staff shifts for AMusicVenue, an independent music venue. You tell staff what shifts are available when they ask or that that they are not. These are the shifts this week:\" + shifts_string)\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Print a welcome message to the user\n",
    "    print(\"Welcome to this simple chatbot! To exit, choose the interrupt button and then press esc.\")\n",
    "    while True:\n",
    "        # Prompt the user for input\n",
    "        user_input = input(\"User: \")\n",
    "        human_message = user_input\n",
    "        print(f\"Human:\\n{user_input}\\n---------------\")\n",
    "        # Create a HumanMessage object with the user's input and add it to the messages list\n",
    "        messages.append(HumanMessage(human_message))\n",
    "\n",
    "        # Assign a blank string that will be added to from the response chunks\n",
    "        response_content = \"\"\n",
    "\n",
    "        print(\"AI: \")\n",
    "        # Stream the response from the chatbot and append each chunk to a string\n",
    "        for chunk in nova_chat.stream(messages):\n",
    "            # Extract text from Nova's structured response format\n",
    "            if hasattr(chunk, 'content') and chunk.content:\n",
    "                if isinstance(chunk.content, list):\n",
    "                    for item in chunk.content:\n",
    "                        if isinstance(item, dict) and item.get('type') == 'text':\n",
    "                            text = item.get('text', '')\n",
    "                            print(text, end=\"\", flush=True)\n",
    "                            response_content += text\n",
    "                else:\n",
    "                    print(chunk.content, end=\"\", flush=True)\n",
    "                    response_content += chunk.content\n",
    "        ai_message = AIMessage(response_content)\n",
    "\n",
    "        # Append the AI message to the messages list\n",
    "        messages.append(ai_message)\n",
    "        print(f\"\\n---------------\")\n",
    "\n",
    "# Handle the KeyboardInterrupt exception (when the user presses esc)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Solution:</b> Select if you need to see the solution.</summary>\n",
    "    \n",
    "<br/>\n",
    "\n",
    "```python\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a chatbot built for scheduling staff shifts for AMusicVenue, an independent music venue. You tell staff what shifts are available when they ask or that that they are not. These are the shifts this week:\" + shifts_string)\n",
    "]\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "52. Input the initial message \"This is *your name*, I want to work Saturday.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "53. Continue to respond to its questions, seeing that the chatbot now has the context required to make intelligent staffing decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "54. To exit, choose **Interrupt** from the main notebook editor toolbar, and then press the **Esc**/**esc** key.\n",
    "\n",
    "**Warning:** If a pop up appears asking if \"want to restart the kernel\", choose **cancel** and then press the the **Esc**/**esc** key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/interrupt.png\">\n",
    "\n",
    "***Image description**: The *Interrupt* key within the IDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain has the tools to go even further: handling the logic, parsing, and secondary model invocation that would be required to update *shifts.csv* after a staff-member has agreed to take a shift, but you will not be learning those in this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task complete**: You used LangChain to add statefullness and context to your staffing chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "You have completed this notebook. To continue to the next part of the lab, do the following:\n",
    "\n",
    "- Close this notebook file.\n",
    "- Return to the lab instructions and continue with the **Conclusion** section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
