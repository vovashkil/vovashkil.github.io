{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "729b6646-3ad1-422e-9568-e958018522e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# <span style=\"color:blue\">Time Complexity\n",
    "AWS CLOUD INSTITUTE: PROVIDED FOR EDUCATIONAL INSTRUCTIONAL PURPOSES ONLY."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "765db471-34aa-4c70-8c71-222e6bf2ec52",
   "metadata": {},
   "source": [
    "Time complexity measures the relative efficiency of an algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a52163-d065-4652-8359-a6203a289408",
   "metadata": {},
   "source": [
    "#### Measuring time with Python's Time Libray\n",
    "If we're going to compare time efficiency, let's use a Python module to measure it. There are a few available choices, and we'll use the **time** module (https://docs.python.org/3/library/time.html). I'll also use the random module to generate random numbers for some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d268b-5421-4438-b70f-7103c762fd88",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224ab285-851f-4574-96d7-bb88779b8d52",
   "metadata": {},
   "source": [
    "## Constant Time Complexity: O(1)\n",
    "A few non-repetitive operations are practically instanteneous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98eda53-faef-44ef-8c93-b0cd0363e6c2",
   "metadata": {},
   "source": [
    "### Algorithm example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d851d-e185-4f78-bca3-1ccdadaa81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_numbers(x , n):\n",
    "    return x + n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2e1c48-2d57-42cb-9060-74e00b2c5c9f",
   "metadata": {},
   "source": [
    "#### Time Complexity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39245760-70ea-4e0d-a44b-abd98785ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "# do a couple operations\n",
    "x = 10\n",
    "n = 30\n",
    "print(f\"{x} + {n} = \", add_numbers(x, n))\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"Ellapsed time: {(end_time - start_time):.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00fc1a3-cf33-49a3-ac84-1262de5259d7",
   "metadata": {},
   "source": [
    "<br>We say these **few quick, non-repeatitice operations**, occur in **\"Constant Time\"**, and use the notation **O(1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183f196c-59b8-4e36-bcd6-3af8c2fd65e0",
   "metadata": {},
   "source": [
    "## Linear Time Complexity: O(n)\n",
    "Repeatitive steps in a single loop are still pretty fast, as long as I'm not significantly changing the number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdf6674-9bcd-4d8f-b41e-a855245b04eb",
   "metadata": {},
   "source": [
    "### Algorithm example: Linear Search\n",
    "The linear search we looked at in an earlier session, is a classic example of a O(n) algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a77d9-4996-468d-8a3c-cfdcf6866fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_search(items, search_value):\n",
    "    for i in range(len(items)):\n",
    "        if items[i] == search_value:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee991041-d71b-4023-a071-f097f93fc268",
   "metadata": {},
   "source": [
    "#### Time Complexity Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bfd165-9dce-4a5d-9b28-72a4f430f165",
   "metadata": {},
   "source": [
    "##### Define the list sizes I want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa15753-1248-4850-a1a3-7cba1427e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sizes = [100, 150, 200, 1000, 10000, 100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3893a1-ae13-4d26-8c51-5c23d3da5e02",
   "metadata": {},
   "source": [
    "##### Iterate to create lists for each test size, and observe the average performance for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b47670-deb5-4537-a89b-81ba9848ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all requested list sizes\n",
    "for list_size in list_sizes:\n",
    "    \n",
    "    # Creata a set of unique keys for the specified list_size\n",
    "    str_set = set({})\n",
    "    while len(str_set) < list_size:\n",
    "        # generate a very large random integer, convert it to a string, and add to set\n",
    "        str_set.add(str(random.randint(0, 1000000000)))\n",
    "    \n",
    "    # convert the set to a list\n",
    "    str_list = list(str_set)\n",
    "\n",
    "    # generate some random keys to searcho for\n",
    "    random_keys = []\n",
    "    for x in range(10):\n",
    "        random_keys.append(str_list[random.randint(0, len(str_list) - 1)])\n",
    "\n",
    "    print(f\"\\n------------------ Searching {len(str_list):,d} elements ------------------\")\n",
    "    \n",
    "    # initialize total linear search time\n",
    "    total_linear_search_time = 0\n",
    "                         \n",
    "    # iterate through search words\n",
    "    for search_key in random_keys:  \n",
    "        # start timer\n",
    "        start_time = time.perf_counter()\n",
    "    \n",
    "        # perform linear search\n",
    "        idx = linear_search(str_list, search_key)\n",
    "    \n",
    "        # stop timer\n",
    "        end_time = time.perf_counter()\n",
    "       \n",
    "        # accumulate the search times so we can average in the end\n",
    "        total_linear_search_time += (end_time - start_time)\n",
    "        \n",
    "    # calculate final average across all searches\n",
    "    avg_linear_search_time = total_linear_search_time / len(random_keys)\n",
    "    print(f\"Average linear search time: {avg_linear_search_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d18469-a14d-4303-a5de-6d17f9dda62a",
   "metadata": {},
   "source": [
    "#### Changes in the same order of magnitude won't make a big difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9ea799-f0f2-45dc-a013-5adcc6f6b12e",
   "metadata": {},
   "source": [
    "It took a loop 1,000 times bigger to begin making a significant difference. Another fancy way of saying this, is that **only a change of a significant \"order of magnitute\", makes a significant difference**. That's what the **\"O\" in the Big O notation** stands for: *\"Order of\"*.\n",
    "\n",
    "In this case, where we have a **single loop**, that will only change the number of steps depending on one variable, we say they occur in **\"Linear Time\"**, and use the notation **O(n)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d572351d-fcea-4cb4-a4c2-c8e3395ddf7f",
   "metadata": {},
   "source": [
    "## Quadratic Time Complexity: O(n<sup>2</sup>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf1dd66-556c-49c0-aae6-471ef2f5b666",
   "metadata": {},
   "source": [
    "What if we have a **loop, inside a loop**? That's what we saw in Bubble Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf674f-0882-4dea-a985-52442a344e23",
   "metadata": {},
   "source": [
    "### Algorithm example: Bubble Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a6b027-4852-43de-817f-e71fff066054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort(my_list):\n",
    "    \"\"\"\n",
    "    Sorts the given list using the Bubble Sort algorithm.\n",
    "    This algorithm modifies the list in place.\n",
    "    \"\"\"\n",
    "    # Get the length of the list\n",
    "    n = len(my_list)\n",
    "\n",
    "    # Outer loop to traverse through the list\n",
    "    for i in range(n):\n",
    "        # Inner loop to compare adjacent elements\n",
    "        for j in range(0, n-i-1):\n",
    "            # Compare adjacent elements\n",
    "            if my_list[j] > my_list[j+1]:\n",
    "                # Swap elements if they are in the wrong order\n",
    "                my_list[j], my_list[j+1] = my_list[j+1], my_list[j]\n",
    "                \n",
    "    # Return the sorted list\n",
    "    return my_list  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3180dfd3-4f62-4a64-8c06-4d8778859219",
   "metadata": {},
   "source": [
    "#### Time Complexity Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f213e775-9d60-4b6a-bb67-ba0db4aaca07",
   "metadata": {},
   "source": [
    "##### Define the list sizes I want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fef6c0b-e69f-40ac-965e-759d49df58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sizes = [100, 1000, 10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84785ec2-a9bc-4d63-a05b-02d7afdbbd2e",
   "metadata": {},
   "source": [
    "##### Iterate to create lists for each test size, and observe the average performance for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd92039-50c2-480b-88b6-5f6ab20cc8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all requested list sizes\n",
    "for list_size in list_sizes:\n",
    "    \n",
    "    # Creata a set of unique keys for the specified list_size\n",
    "    str_set = set({})\n",
    "    while len(str_set) < list_size:\n",
    "        # generate a very large random integer, convert it to a string, and add to set\n",
    "        str_set.add(str(random.randint(0, 1000000000)))\n",
    "    \n",
    "    # convert the set to a list\n",
    "    str_list = list(str_set)\n",
    "\n",
    "    # generate some random keys to searcho for\n",
    "    random_keys = []\n",
    "    for x in range(10):\n",
    "        random_keys.append(str_list[random.randint(0, len(str_list) - 1)])\n",
    "\n",
    "    print(f\"\\n------------------ Sorting {len(str_list):,d} elements ------------------\")\n",
    "    \n",
    "    # start timer\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    # sort using merge_sort\n",
    "    sorted_list = bubble_sort(str_list)\n",
    "    \n",
    "    # stop timer and calculate elapsed time\n",
    "    end_time = time.perf_counter()\n",
    "    bubble_sort_time = end_time - start_time\n",
    "    \n",
    "    # print sorted function time\n",
    "    print(f\"Bubble sort time: {bubble_sort_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00dbc59-6713-4da9-952f-9f4a96613da5",
   "metadata": {},
   "source": [
    "#### Changes that are squared, will make an impact much quicker ...\n",
    "With a small number like \"100\", even this is pretty fast. It's good to remember that even a bad algorithm will probably run fast if you only have a few steps to run.\n",
    "\n",
    "However, by the time we got to 10,000, the performance had deterioted **a lot**. If I went up to 100,000 , it would probably take minutes, or timed out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355af8ab-a835-4ee1-8756-2e5d7393dbad",
   "metadata": {},
   "source": [
    "So moral of the story is, when you have **loops insides loops**, you need to be **careful** with **how many iterations** you have, because they can **significantly change the order of magnitute**. We say they occur in **\"Quadratic Time\"**, and use the notation **O(n<sup>2</sup>)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c0f5ea-03ea-499e-b427-b7d9d37690cb",
   "metadata": {},
   "source": [
    "## Logarithmic Time Complexity: O(log n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07754c22-cd62-4dba-b56b-f2e2680a7ff4",
   "metadata": {},
   "source": [
    "Don't get scared with the Math. The simple question is, what if I have a **loop** that **keeps splitting something in half**, over and over. For instance\n",
    "```\n",
    "while n > 1:\n",
    "    n = n // 2\n",
    "    print(\"New n is\", n)\n",
    "```\n",
    "We've **already seen multiple algorithms that will split the problem**, in the **\"divide and conquer\" approach**. In **some cases** it's **in** a **iteration** like above, but in **other cases** the **split happens via recursion**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52397341-57ed-4cd2-b535-918dd0dcf8f0",
   "metadata": {},
   "source": [
    "### Algortithm example: binary search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f668b-4fd7-4987-95db-01be4b30ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search_loop(items, search_value):\n",
    "    '''\n",
    "    This method will search for an item in a list of ascending order.\n",
    "    It will retur the index of the item if found, or -1 if not found.\n",
    "    '''\n",
    "\n",
    "    # initialize the start and end of our loop, which will be updated as the search progresses\n",
    "    start = 0\n",
    "    end = len(items) - 1\n",
    "\n",
    "    # continue the loop as long as start is <= to end. If we \"cross over\", and the end is smaller\n",
    "    # it will mean that we never found the item\n",
    "    while start <= end:\n",
    "        # split the search space in half, by getting the middle value between the current start and end\n",
    "        middle = (start + end) // 2\n",
    "\n",
    "        # if the search value is equal to the middle value, then we found it, so return the index\n",
    "        if items[middle] == search_value:\n",
    "            return middle\n",
    "        # else, if the search value is less than the middle value, update the end to look at the lower half\n",
    "        elif search_value < items[middle]:\n",
    "            end = middle - 1\n",
    "        # else, the search value is greater than the middle value, so update the start to look at the upper half\n",
    "        else:\n",
    "            start = middle + 1\n",
    "\n",
    "    # if we get here, we never found the item, so return -1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f4a12c-ac53-4bce-9e03-33fa11d371ca",
   "metadata": {},
   "source": [
    "#### Time Complexity Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc428da-2e23-4ec6-be92-5e5472c3e2b1",
   "metadata": {},
   "source": [
    "##### Define the list sizes I want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d085d-86ce-42ac-a1ca-bea01edf8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sizes = [100, 1000, 10000, 100000, 1000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f9ffb-3e2b-49a5-9645-49430680526c",
   "metadata": {},
   "source": [
    "##### Iterate to create lists for each test size, and observe the average performance for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d784bf46-474c-42bd-b402-5e456449c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all requested list sizes\n",
    "for list_size in list_sizes:\n",
    "    \n",
    "    # Creata a set of unique keys for the specified list_size\n",
    "    str_set = set({})\n",
    "    while len(str_set) < list_size:\n",
    "        # generate a very large random integer, convert it to a string, and add to set\n",
    "        str_set.add(str(random.randint(0, 1000000000)))\n",
    "    \n",
    "    # convert the set to a list\n",
    "    str_list = list(str_set)\n",
    "\n",
    "    # generate some random keys to searcho for\n",
    "    random_keys = []\n",
    "    for x in range(10):\n",
    "        random_keys.append(str_list[random.randint(0, len(str_list) - 1)])\n",
    "\n",
    "    print(f\"\\n------------------ Searching {len(str_list):,d} elements ------------------\")\n",
    "    \n",
    "    # initialize total linear search time\n",
    "    total_linear_search_time = 0\n",
    "                         \n",
    "    # iterate through search words\n",
    "    for search_key in random_keys:  \n",
    "        # start timer\n",
    "        start_time = time.perf_counter()\n",
    "    \n",
    "        # perform linear search\n",
    "        idx = binary_search_loop(str_list, search_key)\n",
    "    \n",
    "        # stop timer\n",
    "        end_time = time.perf_counter()\n",
    "       \n",
    "        # accumulate the search times so we can average in the end\n",
    "        total_linear_search_time += (end_time - start_time)\n",
    "        \n",
    "    # calculate final average across all searches\n",
    "    avg_linear_search_time = total_linear_search_time / len(random_keys)\n",
    "    print(f\"Average linear search time: {avg_linear_search_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63381cb7-171f-4d58-8ae3-ef7723e2d4aa",
   "metadata": {},
   "source": [
    "#### How does the performance scale?\n",
    "As we can see, with the ninary search our performance barely changed even going up to 1,000,000 items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be7fe6-4e22-4ac1-a2da-d97307912452",
   "metadata": {},
   "source": [
    "So moral of the story is, when you an **alorithm**, **where steps are based on something being split in half multiple times**, the **performance is great**. That's because as we can see in the output, the number of steps stay very small, even for large numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a01beb7-201d-4e15-b8c1-ca9fbd7c2988",
   "metadata": {},
   "source": [
    "You don't need to understand the Math to see the number of iterations will grow very slowly. We say that these **algorithms** that keep **splitting the steps in half** have occur in \"**Logarithmic Time**\", and use the notation **O(log n)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3148e7-4bca-4010-811d-d21579c5d18e",
   "metadata": {},
   "source": [
    "## Quasilinear time complexity: O(n log n) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fd1d50-8b93-42a8-baa4-58765819832f",
   "metadata": {},
   "source": [
    "**What if** you have an **algorithm that performs in O(log n)**, which we know is very fast, **but you repeat that *n* times**. That combination of linear and logarithmic operations is what we call Quasilinear time complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acebeaf-bc90-4db6-9f91-fbf7f3c0c38d",
   "metadata": {},
   "source": [
    "### Algorithm example: Quicksort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cb869a-8c42-46de-9565-24633d88876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quicksort(my_list):\n",
    "    '''\n",
    "    Implements the quicksort algorithm\n",
    "    '''\n",
    "    # Base case: if the list has one or less elements, it's considered sorted\n",
    "    if len(my_list) <= 1:\n",
    "        return my_list \n",
    "\n",
    "    # assign the pivot point as the first element\n",
    "    pivot = my_list[0]\n",
    "\n",
    "    # Create two sublists, one for items less than the pivot and one for greater\n",
    "    # These are essentially for loops, but we use Python list comprehension to do each on one line\n",
    "    less_than_pivot = [i for i in my_list[1:] if i <= pivot] \n",
    "    greater_than_pivot = [i for i in my_list[1:] if i > pivot]\n",
    "\n",
    "    # Now recursively call quicksort on the left and right sub-lists\n",
    "    # In the end, we'll be returning <sorted left list>, pivot, <sorted right list>\n",
    "    return quicksort(less_than_pivot) + [pivot] + quicksort(greater_than_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e670c6a-3092-4885-97bb-3d8d5d8c142c",
   "metadata": {},
   "source": [
    "#### Time Complexity Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607f0238-743d-4d92-a8ec-d88c18188603",
   "metadata": {},
   "source": [
    "##### Define the list sizes I want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4770fbf3-c416-4f52-9b09-700a55fd2407",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sizes = [100, 1000, 10000, 100000, 1000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc9fec2-159a-4f66-86cb-34e54ac2d2b1",
   "metadata": {},
   "source": [
    "##### Iterate to create lists for each test size, and observe the average performance for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911075f3-5782-4a9b-991a-4d6a4646954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all requested list sizes\n",
    "for list_size in list_sizes:\n",
    "    \n",
    "    # Creata a set of unique keys for the specified list_size\n",
    "    str_set = set({})\n",
    "    while len(str_set) < list_size:\n",
    "        # generate a very large random integer, convert it to a string, and add to set\n",
    "        str_set.add(str(random.randint(0, 1000000000)))\n",
    "    \n",
    "    # convert the set to a list\n",
    "    str_list = list(str_set)\n",
    "\n",
    "    # generate some random keys to searcho for\n",
    "    random_keys = []\n",
    "    for x in range(10):\n",
    "        random_keys.append(str_list[random.randint(0, len(str_list) - 1)])\n",
    "\n",
    "    print(f\"\\n------------------ Sorting {len(str_list):,d} elements ------------------\")\n",
    "    \n",
    "    # start timer\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    # sort using merge_sort\n",
    "    sorted_list = quicksort(str_list)\n",
    "    \n",
    "    # stop timer and calculate elapsed time\n",
    "    end_time = time.perf_counter()\n",
    "    quicksort_time = end_time - start_time\n",
    "    \n",
    "    # print sorted function time\n",
    "    print(f\"Quicksort time: {quicksort_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75764f60-b798-4f91-b694-a49cdfc88d43",
   "metadata": {},
   "source": [
    "#### How did that fare?\n",
    "**If** you **compare to** the **O(log n)** of binary search, this one **didn't stay super fast forever**. **But** even for 1,000,000 items, it did complete in a reasonable time. If you **compare** that **to the **O(n<sup>2</sup>)** bubble sort**, that's much **much faster**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571157e-210e-48ba-8666-3673d735bcd2",
   "metadata": {},
   "source": [
    "## Factorial time complexity: O(n!) \n",
    "An algorithm has a factorial time complexity when its runtime grows factorially based on the size of the input data. \n",
    "\n",
    "For those who don't know, the **\"factorial of n\"** is **represented as \"n!\"**, and it it's the product of n * (n - 1) * (n - 2) * ... * 1.\n",
    "\n",
    "Examples:\n",
    "- 3! = 3 * 2 * 1 = 6\n",
    "- 4! = 4 * 3 * 2 * 1 = 24\n",
    "- 5! = 5 * 4 * 3 * 2 * 1 = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9438adf-afaf-4f2a-b59f-acc08bd43050",
   "metadata": {},
   "source": [
    "This may seem like an unlikely thing to need in computing, but it's actually **frequently used in combinatorial and statistics problems**. \n",
    "\n",
    "One of the **simplest examples**, is **generating permutations**. For instance, imagine **you have a class of students**, and you want to decide **how many possible ways** you can **line up the students for a class** picture. That would be a **permutation problem**. **Depending on how many** students you have in the class, that **number can be very very high**. For instance, even in a class of 15 students, there would be 1,307,674,368,000 possible arrangements. That's in the order of 1 trillion!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee70079-19fd-4afe-9bad-2f3cfa962194",
   "metadata": {},
   "source": [
    "### Algorithm example: generating permutations\n",
    "The algorithm or permutations is a classic recursion example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa93f1c-3856-455c-8e99-77634d5621f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutations(elements, current_permutation=[], all_permutations = []): \n",
    "    # Recursion exit: if there are no more elements to add, add the current permutation to result list\n",
    "    if not elements: \n",
    "        all_permutations.append(current_permutation) \n",
    "    else:\n",
    "        # iterate through list of elemenst\n",
    "        for i in range(len(elements)):\n",
    "            # build a list of all items except the current element\n",
    "            remaining_elements = elements[:i] + elements[i + 1:] \n",
    "            # now recursively generate permutations of all the other items, while adding the current element to the current permutation\n",
    "            generate_permutations(remaining_elements, current_permutation + [elements[i]], all_permutations)\n",
    "\n",
    "    # return the list of all permutations\n",
    "    return all_permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7506a9cf-d120-4f37-bd6a-3676b551f989",
   "metadata": {},
   "source": [
    "##### Very quick example of the execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd0f9d1-f1d9-400f-8bd3-89af5f03d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "students = [\"John\", \"Diego\", \"Ana\", \"Soo-jin Ki\"]\n",
    "all_permutations = generate_permutations(students)\n",
    "for permutation in all_permutations:\n",
    "    print(permutation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5137c078-59c6-473e-9434-557d59fcbb30",
   "metadata": {},
   "source": [
    "Wow! That's a lot of options for just 4 students!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752bd751-2c74-4747-b521-6fe34ba820ee",
   "metadata": {},
   "source": [
    "#### Time Complexity Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b1a3b3-f2aa-40f3-95f3-37cd1d2caaee",
   "metadata": {},
   "source": [
    "##### Define the list sizes I want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad17eb8f-5ab6-4728-8dd9-5da940dbc233",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sizes = [2 , 4, 6, 8, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89126df9-96ac-4c5c-9db2-5b9c76e8e447",
   "metadata": {},
   "source": [
    "##### Iterate to create lists for each test size, and observe the average performance for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0973e5b8-5c93-4c80-8258-cc5483f952e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all requested list sizes\n",
    "for list_size in list_sizes:\n",
    "    \n",
    "    # Creata a set of unique keys for the specified list_size\n",
    "    str_set = set({})\n",
    "    while len(str_set) < list_size:\n",
    "        # generate a very large random integer, convert it to a string, and add to set\n",
    "        str_set.add(str(random.randint(0, 1000000000)))\n",
    "    \n",
    "    # convert the set to a list\n",
    "    str_list = list(str_set)\n",
    "\n",
    "    print(f\"\\n------------------ Generating permutations for {len(str_list):,d} elements ------------------\")\n",
    "    \n",
    "    # start timer\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    # sort using merge_sort\n",
    "    permutations = generate_permutations(str_list)\n",
    "    \n",
    "    # stop timer and calculate elapsed time\n",
    "    end_time = time.perf_counter()\n",
    "    permutations_time = end_time - start_time\n",
    "    \n",
    "    # print sorted function time\n",
    "    print(f\"Generating permutations time: {permutations_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a12faa-deab-4d8f-8d68-f06b2ffccd50",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### How did that fare?\n",
    "Did you see that?! Good thing I didn't try this for 1,000,000. We would all be long gone for this earth before it was done :-)\n",
    "\n",
    "In fact, you can see the performance was already going downhill fast, even in a number as little as 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9459fc0-f8f3-4955-ad75-cc74de65174b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
